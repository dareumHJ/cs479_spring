{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMAz/CGjvBXnhMNKh7Qb3wH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dareumHJ/cs479_spring/blob/main/PointNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_o89DSMFzoX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class STNKd(nn.Module):\n",
        "    # T-Net a.k.a. Spatial Transformer Network\n",
        "    def __init__(self, k: int):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.conv1 = nn.Sequential(nn.Conv1d(k, 64, 1), nn.BatchNorm1d(64))\n",
        "        self.conv2 = nn.Sequential(nn.Conv1d(64, 128, 1), nn.BatchNorm1d(128))\n",
        "        self.conv3 = nn.Sequential(nn.Conv1d(128, 1024, 1), nn.BatchNorm1d(1024))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, k * k),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input: [B,k,N]\n",
        "        Output: [B,k,k]\n",
        "        \"\"\"\n",
        "        B = x.shape[0]\n",
        "        device = x.device\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = torch.max(x, 2)[0]\n",
        "\n",
        "        x = self.fc(x)\n",
        "\n",
        "        # Followed the original implementation to initialize a matrix as I.\n",
        "        identity = (\n",
        "            Variable(torch.eye(self.k, dtype=torch.float))\n",
        "            .reshape(1, self.k * self.k)\n",
        "            .expand(B, -1)\n",
        "            .to(device)\n",
        "        )\n",
        "        x = x + identity\n",
        "        x = x.reshape(-1, self.k, self.k)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PointNetFeat(nn.Module):\n",
        "    \"\"\"\n",
        "    Corresponds to the part that extracts max-pooled features.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_transform: bool = False,\n",
        "        feature_transform: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.input_transform = input_transform\n",
        "        self.feature_transform = feature_transform\n",
        "\n",
        "        if self.input_transform:\n",
        "            self.stn3 = STNKd(k=3)\n",
        "        if self.feature_transform:\n",
        "            self.stn64 = STNKd(k=64)\n",
        "\n",
        "        # point-wise mlp\n",
        "        # TODO : Implement point-wise mlp model based on PointNet Architecture.\n",
        "        self.point_wise_mlp = nn.Sequential(\n",
        "            nn.Conv1d(3, 64, 1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 128, 1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 1024, 1),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, pointcloud):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            - pointcloud: [B,N,3]\n",
        "        Output:\n",
        "            - Global feature: [B,1024]\n",
        "            - ...\n",
        "        \"\"\"\n",
        "        B, N, C = pointcloud.shape\n",
        "\n",
        "        # Input Transform (optional)\n",
        "        if self.input_transform:\n",
        "          trans3 = self.stn3(pointcloud.permute(0, 2, 1))  # [B, 3, 3]\n",
        "          pointcloud = torch.bmm(trans3, pointcloud.permute(0, 2, 1))  # [B, 3, N]\n",
        "          pointcloud = pointcloud.permute(0, 2, 1)  # [B, N, 3]\n",
        "\n",
        "        # Point-wise MLP\n",
        "        output = self.point_wise_mlp(pointcloud.permute(0, 2, 1))\n",
        "\n",
        "        # Feature Transform (optional)\n",
        "        if self.feature_transform:\n",
        "          trans64 = self.stn64(output)\n",
        "          output = torch.bmm(trans64, output)\n",
        "\n",
        "        # Global feauter extraction (Max pooling)\n",
        "        output = torch.max(output, 2)[0]  # [B, 1024]\n",
        "\n",
        "        return output\n",
        "\n",
        "class PointNetCls(nn.Module):\n",
        "    def __init__(self, num_classes, input_transform, feature_transform):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # extracts max-pooled features\n",
        "        self.pointnet_feat = PointNetFeat(input_transform, feature_transform)\n",
        "\n",
        "        # returns the final logits from the max-pooled features.\n",
        "        # TODO : Implement MLP that takes global feature as an input and return logits.\n",
        "\n",
        "    def forward(self, pointcloud):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            - pointcloud [B,N,3]\n",
        "        Output:\n",
        "            - logits [B,num_classes]\n",
        "            - ...\n",
        "        \"\"\"\n",
        "        # TODO : Implement forward function.\n",
        "        pass\n",
        "\n",
        "\n",
        "class PointNetPartSeg(nn.Module):\n",
        "    def __init__(self, m=50):\n",
        "        super().__init__()\n",
        "\n",
        "        # returns the logits for m part labels each point (m = # of parts = 50).\n",
        "        # TODO: Implement part segmentation model based on PointNet Architecture.\n",
        "        pass\n",
        "\n",
        "    def forward(self, pointcloud):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            - pointcloud: [B,N,3]\n",
        "        Output:\n",
        "            - logits: [B,50,N] | 50: # of point labels\n",
        "            - ...\n",
        "        \"\"\"\n",
        "        # TODO: Implement forward function.\n",
        "        pass\n",
        "\n",
        "\n",
        "class PointNetAutoEncoder(nn.Module):\n",
        "    def __init__(self, num_points):\n",
        "        super().__init__()\n",
        "        self.pointnet_feat = PointNetFeat()\n",
        "\n",
        "        # Decoder is just a simple MLP that outputs N x 3 (x,y,z) coordinates.\n",
        "        # TODO : Implement decoder.\n",
        "\n",
        "    def forward(self, pointcloud):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            - pointcloud [B,N,3]\n",
        "        Output:\n",
        "            - pointcloud [B,N,3]\n",
        "            - ...\n",
        "        \"\"\"\n",
        "        # TODO : Implement forward function.\n",
        "        pass\n",
        "\n",
        "\n",
        "def get_orthogonal_loss(feat_trans, reg_weight=1e-3):\n",
        "    \"\"\"\n",
        "    a regularization loss that enforces a transformation matrix to be a rotation matrix.\n",
        "    Property of rotation matrix A: A*A^T = I\n",
        "    \"\"\"\n",
        "    if feat_trans is None:\n",
        "        return 0\n",
        "\n",
        "    B, K = feat_trans.shape[:2]\n",
        "    device = feat_trans.device\n",
        "\n",
        "    identity = torch.eye(K).to(device)[None].expand(B, -1, -1)\n",
        "    mat_square = torch.bmm(feat_trans, feat_trans.transpose(1, 2))\n",
        "\n",
        "    mat_diff = (identity - mat_square).reshape(B, -1)\n",
        "\n",
        "    return reg_weight * mat_diff.norm(dim=1).mean()\n"
      ]
    }
  ]
}